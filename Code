#Image sharpening
      "source": [
        "def sharpen_image(image, sigma=1.5, strength=1.5):\n",
        "    blurred = cv2.GaussianBlur(image, (0, 0), sigma)\n",
        "    sharpened = cv2.addWeighted(image, 1.0 + strength, blurred, -strength, 0)\n",
        "    return sharpened\n",
        "def detect_and_circle_iris(image):\n",
        "    eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=11, minSize=(45, 45), maxSize=(100,100))\n",
        "    for (x, y, w, h) in eyes:\n",
        "        center = (x + w // 2, y + h // 2)\n",
        "        radius = int(0.15 * max(w, h))\n",
        "        cv2.circle(image, center, radius, (0, 255, 0), 2)\n",
        "    return image, eyes"
      ]

#Iris detection
"source": [
        "input_dir = \"/content/drive/MyDrive/rpp/FSVP-PBP-main/FSVP-PBP-main/FSVP-PBP Database/Subject {}/Frames/frame{}.png\"\n",
        "output_dir = \"/content/drive/MyDrive/rpp/FSVP-PBP-main/FSVP-PBP-main/iris_detection/Subject {}/Frames/frame{}.png\"\n",
        "for i in range(1,201):\n",
        "    print(\"*************************************\",i,\"********************************************\")\n",
        "    for j in range(10):\n",
        "        subject_input_dir = input_dir.format(i, j)\n",
        "        subject_output_dir = output_dir.format(i, j)\n",
        "        if os.path.isfile(subject_input_dir):\n",
        "            print(subject_input_dir,\"   \")\n",
        "            image_path = subject_input_dir\n",
        "            nir_image = cv2.imread(subject_input_dir)\n",
        "            original_image = cv2.imread(subject_input_dir)\n",
        "            sharpened_image = sharpen_image(nir_image)\n",
        "            result_image, eyes = detect_and_circle_iris( sharpened_image)\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            plt.subplot(1, 3, 1)\n",
        "            plt.imshow(cv2.cvtColor( original_image, cv2.COLOR_BGR2RGB))\n",
        "            plt.title('Original Image')\n",
        "            plt.subplot(1, 3, 2)\n",
        "            plt.imshow(cv2.cvtColor(sharpened_image, cv2.COLOR_BGR2RGB))\n",
        "            plt.title('Sharpened Image')\n",
        "            plt.subplot(1, 3, 3)\n",
        "            plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
        "            plt.title('Iris Detection')\n",
        "            plt.show()"
      ]

#ROI extraction
"source": [
        "def detect_roi(image_path, eyes_coordinates):\n",
        "    image = cv2.imread(image_path)\n",
        "    inter_ocular_distance = abs(((eyes_coordinates[1][0] + eyes_coordinates[1][2])) - ((eyes_coordinates[0][0] + eyes_coordinates[0][2] )))\n",
        "    roi_width = int(1.62 * inter_ocular_distance)\n",
        "    roi_height = int(0.5 * inter_ocular_distance)\n",
        "    periocular_x = eyes_coordinates[1][0] - int(0.62 * roi_width)\n",
        "    periocular_y = eyes_coordinates[1][1] - int(0.25 * roi_height)\n",
        "    forehead_x = eyes_coordinates[1][0] - int(0.62 * roi_width)\n",
        "    forehead_y = eyes_coordinates[1][1] - int(0.9 * inter_ocular_distance)\n",
        "    periocular_roi = image[periocular_y:periocular_y + roi_height, periocular_x:periocular_x + roi_width]\n",
        "    forehead_roi = image[forehead_y:forehead_y + roi_height, forehead_x:forehead_x + roi_width]\n",
        "    return periocular_roi, forehead_roi\n"
      ]

#Extracting ROI and writing into separate folder
"source": [
        "def create_folder(folder_path):\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "def main():\n",
        "    input_dir = \"/content/drive/MyDrive/rpp/FSVP-PBP-main/FSVP-PBP-main/FSVP-PBP Database/Subject {}/Frames/frame{}.png\"\n",
        "    output_base_dir = \"/content/drive/MyDrive/rpp/FSVP-PBP-main/FSVP-PBP-main/\"\n",
        "    for i in range(1,201):\n",
        "        print(\"*************************************\", i, \"********************************************\")\n",
        "        for j in range(10):\n",
        "            subject_input_dir = input_dir.format(i, j)\n",
        "            subject_output_dir1 = output_base_dir + \"periocular/Subject {}/\".format(i)\n",
        "            subject_output_dir2 = output_base_dir + \"forehead/Subject {}/\".format(i)\n",
        "            if os.path.isfile(subject_input_dir):\n",
        "                print(subject_input_dir)\n",
        "                create_folder(subject_output_dir1)\n",
        "                create_folder(subject_output_dir2)\n",
        "                image_path = subject_input_dir\n",
        "                nir_image = cv2.imread(subject_input_dir)\n",
        "                original_image = cv2.imread(subject_input_dir)\n",
        "                sharpened_image = sharpen_image(nir_image)\n",
        "                result_image, eyes_coordinates = detect_and_circle_iris(nir_image)\n",
        "                if len(eyes_coordinates) >= 2:\n",
        "                    periocular_roi, forehead_roi = detect_roi(image_path, eyes_coordinates)\n",
        "                    plt.imshow(cv2.cvtColor(periocular_roi, cv2.COLOR_BGR2RGB))\n",
        "                    plt.title('Periocular ROI')\n",
        "                    plt.show()\n",
        "                    plt.imshow(cv2.cvtColor(forehead_roi, cv2.COLOR_BGR2RGB))\n",
        "                    plt.title('Forehead ROI')\n",
        "                    plt.show()\n",
        "                    #cv2.imwrite(os.path.join(subject_output_dir1, \"frame{}.png\".format(j)), periocular_roi)\n",
        "                    #cv2.imwrite(os.path.join(subject_output_dir2, \"frame{}.png\".format(j)), forehead_roi)\n",
        "                else:\n",
        "                    print(\"Could not detect both eyes.\")\n",

#ROI enhancement
def dog_clahe(image, sigma1=2, sigma2=3):\n",
        "    blur1 = cv2.GaussianBlur(image, (0, 0), sigmaX=sigma1)\n",
        "    blur2 = cv2.GaussianBlur(image, (0, 0), sigmaX=sigma2)\n",
        "    dog_filtered = blur1 - blur2\n",
        "    dog_clahe = clahe(dog_filtered),
        "    return dog_clahe\n",

#Feature extraction and classification
"source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, concatenate, Dropout, BatchNormalization\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def get_cnn_features(model, generator):\n",
        "    features = model.predict(generator)\n",
        "    return features\n",
        "\n",
        "def model(input_shape, dropout_rate=0.5):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=[2, 2], activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2), strides=[1, 1]))\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=[2, 2], activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2), strides=[1, 1]))\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=[2, 2],activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2), strides=[1, 1]))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    return model\n",
        "\n",
        "def combine_models(model_1, model_2, num_classes):\n",
        "    combined_output = concatenate([model_1.output, model_2.output])\n",
        "    fully_connected_layer = Dense(256, activation='relu')(combined_output)\n",
        "    fully_connected_layer = Dropout(0.5)(fully_connected_layer)\n",
        "    combined_model = Model(inputs=[model_1.input, model_2.input], outputs=fully_connected_layer)\n",
        "    return combined_model\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'gamma': [0.001, 0.01, 0.1, 1, 'scale', 'auto']\n",
        "}\n",
        "\n",
        "\n",
        "input_size = (128, 233, 1)\n",
        "im_shape = (128, 233)\n",
        "TRAINING_DIR1 = '/content/drive/MyDrive/RPP/rpp/FSVP-PBP-main/FSVP-PBP-main/train/periocular'\n",
        "TEST_DIR1 = '/content/drive/MyDrive/RPP/rpp/FSVP-PBP-main/FSVP-PBP-main/test/periocular'\n",
        "TRAINING_DIR2 = '/content/drive/MyDrive/RPP/rpp/FSVP-PBP-main/FSVP-PBP-main/train/forehead'\n",
        "TEST_DIR2 = '/content/drive/MyDrive/RPP/rpp/FSVP-PBP-main/FSVP-PBP-main/test/forehead'\n",
        "BATCH_SIZE = 50\n",
        "\n",
        "seed = 20\n",
        "data_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "cnn_model_1 = model(input_size)\n",
        "cnn_model_2 = model(input_size)\n",
        "\n",
        "cnn_model_1.add(layers.Dropout(0.5))\n",
        "cnn_model_2.add(layers.Dropout(0.5))\n",
        "\n",
        "num_classes = 200\n",
        "combined_model = combine_models(cnn_model_1, cnn_model_2, num_classes)\n",
        "combined_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "combined_model.build((None, 128, 233, 3))\n",
        "combined_model.summary()\n",
        "\n",
        "train1_generator = data_generator.flow_from_directory(\n",
        "    TRAINING_DIR1, target_size=im_shape, shuffle=False, seed=seed,\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\", color_mode='grayscale'\n",
        ")\n",
        "\n",
        "train2_generator = data_generator.flow_from_directory(\n",
        "    TRAINING_DIR2, target_size=im_shape, shuffle=False, seed=seed,\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\", color_mode='grayscale'\n",
        ")\n",
        "\n",
        "train1_labels = train1_generator.classes\n",
        "train2_labels = train2_generator.classes\n",
        "\n",
        "# Extract features from test data\n",
        "test1_generator = data_generator.flow_from_directory(\n",
        "    TEST_DIR1, target_size=im_shape, shuffle=False, seed=seed,\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, color_mode='grayscale'\n",
        ")\n",
        "\n",
        "test2_generator = data_generator.flow_from_directory(\n",
        "    TEST_DIR2, target_size=im_shape, shuffle=False, seed=seed,\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, color_mode='grayscale'\n",
        ")\n",
        "\n",
        "# Get actual labels from the data generators\n",
        "test1_labels = test1_generator.classes\n",
        "test2_labels = test2_generator.classes\n",
        "\n",
        "# Concatenate features and labels\n",
        "train_features = np.concatenate([get_cnn_features(cnn_model_1, train1_generator), get_cnn_features(cnn_model_2, train2_generator)], axis=1)\n",
        "test_features = np.concatenate([get_cnn_features(cnn_model_1, test1_generator), get_cnn_features(cnn_model_2, test2_generator)], axis=1)\n",
        "\n",
        "grid_search = GridSearchCV(SVC(), param_grid, cv=3)\n",
        "grid_search.fit(train_features, train1_labels)\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "\n",
        "test1_predictions = best_svm_model.predict(test_features)\n",
        "accuracy = accuracy_score(test1_labels, test1_predictions)\n",
        "print(f'Accuracy: {accuracy}')\n"
      ]

"source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def model(input_shape):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=[2, 2], activation='relu', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D((2, 2), strides=[1, 1]))\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=[2, 2], activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2), strides=[1, 1]))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    return model\n",
        "\n",
        "def combine_models(model_1, model_2, num_classes):\n",
        "    combined_output = layers.concatenate([model_1.output, model_2.output])\n",
        "    fully_connected_layer = layers.Dense(128, activation='relu')(combined_output)\n",
        "    output_layer = layers.Dense(num_classes, activation='softmax')(fully_connected_layer)\n",
        "    combined_model = models.Model(inputs=[model_1.input, model_2.input], outputs=output_layer)\n",
        "    return combined_model\n",
        "\n",
        "input_size = (128, 233, 1)\n",
        "im_shape = (128, 233)\n",
        "\n",
        "TRAINING_DIR1 = '/content/drive/MyDrive/rpp/FSVP-PBP-main/FSVP-PBP-main/training_100/train/periocular'\n",
        "TEST_DIR1 = '/content/drive/MyDrive/rpp/FSVP-PBP-main/FSVP-PBP-main/training_100/test/periocular'\n",
        "TRAINING_DIR2 = '/content/drive/MyDrive/rpp/FSVP-PBP-main/FSVP-PBP-main/training_100/train/forehead'\n",
        "TEST_DIR2 = '/content/drive/MyDrive/rpp/FSVP-PBP-main/FSVP-PBP-main/training_100/test/forehead'\n",
        "BATCH_SIZE = 19\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "seed = 20\n",
        "data_generator = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "def custom_generator(generator1, generator2):\n",
        "    while True:\n",
        "        batch_x1, batch_y1 = next(generator1)\n",
        "        batch_x2, batch_y2 = next(generator2)\n",
        "        yield [batch_x1, batch_x2], batch_y1\n",
        "\n",
        "train1 = data_generator.flow_from_directory(\n",
        "    TRAINING_DIR1, target_size=im_shape, shuffle=True, seed=seed,\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\", color_mode='grayscale'\n",
        ")\n",
        "train2 = data_generator.flow_from_directory(\n",
        "    TRAINING_DIR2, target_size=im_shape, shuffle=True, seed=seed,\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\", color_mode='grayscale'\n",
        ")\n",
        "\n",
        "test_generator = ImageDataGenerator(rescale=1./255)\n",
        "test1 = test_generator.flow_from_directory(\n",
        "    TEST_DIR1, target_size=im_shape, shuffle=False, seed=seed,\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, color_mode='grayscale'\n",
        ")\n",
        "test2 = test_generator.flow_from_directory(\n",
        "    TEST_DIR2, target_size=im_shape, shuffle=False, seed=seed,\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, color_mode='grayscale'\n",
        ")\n",
        "\n",
        "train_samples = train1.samples\n",
        "num_classes = len(train1.class_indices)\n",
        "print('Classes: ' + str(num_classes))\n",
        "\n",
        "cnn_model_1 = model(input_size)\n",
        "cnn_model_2 = model(input_size)\n",
        "combined_model = combine_models(cnn_model_1, cnn_model_2, num_classes)\n",
        "combined_model.compile(optimizer='adam',\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "combined_model.build((None, 128, 233, 3))\n",
        "combined_model.summary()\n",
        "combined_model.fit(\n",
        "    custom_generator(train1, train2),\n",
        "    steps_per_epoch=train_samples // BATCH_SIZE,\n",
        "    validation_data=custom_generator(test1, test2),\n",
        "    validation_steps=test1.samples // BATCH_SIZE,\n",
        "    epochs=100\n",
        ")\n"
      ]
